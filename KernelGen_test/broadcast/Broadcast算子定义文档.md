# Broadcast算子定义与优化版本说明

## 版本一：基础实现版本

### （1）原始需求
实现基础的Broadcast功能，确保在低维和中维Shape下（如[512, 128, 512]）结果正确，能够处理基本的维度对齐和扩展逻辑，暂不考虑极致的性能优化。

### （2）算子基本信息
- **算子名称**：Broadcast
- **测评设备**：Ascend-snt9b
- **算子类型**：Pointwise
- **功能描述**：将输入张量根据目标形状进行广播扩展，支持从尾部对齐的维度扩展规则，输出与目标形状一致的张量。

### （3）输入参数
| 参数名称 | 数据类型 | 描述 |
| :--- | :--- | :--- |
| x | torch.Tensor | 待广播的输入张量，支持任意维度。 |
| target_shape | torch.Tensor (int64) | 目标形状，由一个一维整型张量表示。 |

### （4）输出参数
| 数据类型 | 描述 |
| :--- | :--- |
| torch.Tensor | 广播后的输出张量，其形状由target_shape指定，数据类型与输入x一致。 |

### （5）自动优化最大迭代轮次
10

### （6）针对性调整与KernelGen优化记档
**未达到测试目标情况**：
在处理高维Shape（如S1: [2048, 2048, 2048]）时，执行时间超过阈值，且APROF显示Global Memory读写耗时占比过高（>80%）。

**Triton代码修改策略**：
1.  **调整BLOCK_SIZE**：默认的BLOCK_SIZE可能较小，导致每个线程块处理的数据量不足，无法充分利用内存带宽。建议将`BLOCK_SIZE`从默认的64或128调整为512或1024，以增加每次数据搬运的粒度。
2.  **向量化加载**：检查生成的Triton代码中是否使用了`tl.load`的掩码参数。对于连续内存区域，移除掩码或确保边界对齐，并尝试使用更大的向量宽度（如`tl.vectorized`提示）进行加载。

**KernelGen工具优化记档**：
- 记录在高维场景下，默认Tiling策略导致的带宽利用率不足问题。
- 建议KernelGen在后续版本中，针对大Shape输入，自动增大默认的Block Size，并优先尝试向量化加载指令。

---

## 版本二：内存访问优化版本

### （1）原始需求
针对高维Shape场景，解决内存访问非连续和带宽利用率低的问题。重点优化数据在Local Memory (UB) 中的复用，减少Global Memory的交互次数，并确保内存访问对齐。

### （2）算子基本信息
- **算子名称**：Broadcast_Opt_Mem
- **测评设备**：Ascend-snt9b
- **算子类型**：Pointwise
- **功能描述**：在基础功能之上，通过优化数据分块策略和内存访问模式，提升高维张量广播的内存带宽利用率。

### （3）输入参数
| 参数名称 | 数据类型 | 描述 |
| :--- | :--- | :--- |
| x | torch.Tensor | 待广播的输入张量。 |
| target_shape | torch.Tensor (int64) | 目标形状。 |

### （4）输出参数
| 数据类型 | 描述 |
| :--- | :--- |
| torch.Tensor | 广播后的输出张量。 |

### （5）自动优化最大迭代轮次
20

### （6）针对性调整与KernelGen优化记档
**未达到测试目标情况**：
虽然内存带宽利用率提升，但在非连续内存访问（如广播维度在中间）的场景下，性能提升不明显，且存在Bank Conflict风险。

**Triton代码修改策略**：
1.  **调整数据布局**：在Triton Kernel中，手动调整`strides`参数。对于需要广播的维度（stride=0），确保生成的代码能够正确处理，避免重复加载。
2.  **多级缓存**：启用`num_stages`参数（例如设置为3或4），利用流水线技术，在计算当前Block的同时预取下一个Block的数据，掩盖内存延迟。
3.  **Group Size调整**：如果存在Bank Conflict，尝试调整访问的Group大小或改变访问步长。

**KernelGen工具优化记档**：
- 记录非连续访问场景下的性能退化现象。
- 建议KernelGen引入自动分析Stride的逻辑，对于Stride为0的广播维度，自动生成常量填充逻辑而非重复加载逻辑。
- 建议工具根据数据类型大小（FP16/BF16），自动计算最优的内存对齐参数（如32字节对齐）。

---

## 版本三：高性能并行与动态Shape优化版本

### （1）原始需求
在内存优化的基础上，进一步挖掘算子性能上限。要求支持动态Shape输入（如shape=-1），消除动态分支开销；利用多核并行和向量化指令，最大化AI Core的吞吐量，满足S1、S2等超高维Shape的严苛性能要求。

### （2）算子基本信息
- **算子名称**：Broadcast_Opt_HighPerf
- **测评设备**：Ascend-snt9b
- **算子类型**：Pointwise
- **功能描述**：全功能的Broadcast算子，支持动态Shape，采用多核并行策略和自适应Tiling，针对昇腾AI处理器架构深度优化，实现极致推理性能。

### （3）输入参数
| 参数名称 | 数据类型 | 描述 |
| :--- | :--- | :--- |
| x | torch.Tensor | 待广播的输入张量，支持动态维度。 |
| target_shape | torch.Tensor (int64) | 目标形状，支持动态值。 |

### （4）输出参数
| 数据类型 | 描述 |
| :--- | :--- |
| torch.Tensor | 广播后的输出张量。 |

### （5）自动优化最大迭代轮次
50

### （6）针对性调整与KernelGen优化记档
**未达到测试目标情况**：
在动态Shape测试用例（S5-S8）中，性能波动大，且多核并行扩展性差（增加核数后性能不线性增长）。

**Triton代码修改策略**：
1.  **动态Shape处理**：确保生成的Triton代码使用`tl.program_id`动态计算索引，避免编译时常量限制。对于动态Shape，在Kernel启动时通过参数传入实际维度。
2.  **并行度调整**：调整Grid的大小（`triton.cdiv`逻辑），确保生成的Block数量足够多，能够填满所有可用的AI Core。对于小Shape，减少Block数量以避免调度开销。
3.  **Wave Scheduling**：如果硬件支持，在Triton调用中启用特定的调度策略（如`num_warps`），针对Broadcast这种计算密度低、访存密度高的算子，适当增加每个Block的Warps数量以隐藏延迟。

**KernelGen工具优化记档**：
- 记录动态Shape场景下的编译和运行时开销问题。
- 建议KernelGen实现自适应Tiling算法：根据输入Tensor的总大小，自动计算最优的`BLOCK_SIZE`和`num_warps`组合。
- 记录多核并行策略，建议工具在生成代码时，自动插入针对Ascend架构的多核调度原语，确保负载均衡。